import numpy as np
import word2vec
import HH
import json
import os
import re

from pick import pick
from sklearn.metrics.pairwise import cosine_similarity

class UltimateMatcher:
    def __init__(self, word2vec_model, resume_data, vacancy_data):
        self.word2vec_model = word2vec_model
        self.resume_object = resume_data
        self.vacancy_object = vacancy_data
        self.description_matcher = Word2VecMatcher(self.word2vec_model)
        self.classification_matcher = SimplyClassificationMatcher()

        self.weights = {
            'semantic': 0.35,
            'multi_criteria': 0.25,
        }
        
    def ultimate_match(self):
        """–ö–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ"""
        results = {}
        # 1. –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ –æ–ø–∏—Å–∞–Ω–∏–π
        results['semantic'] = self.description_matcher.calculate_similarity(self.resume_object, self.vacancy_object)
        # 2. –ú–Ω–æ–≥–æ–∫—Ä–∏—Ç–µ—Ä–∏–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
        results['multi_criteria'] = self.classification_matcher.calculate_multi_criteria_score(self.resume_object, self.vacancy_object)

        final_score = sum(results[match] * self.weights[match] for match in results)

        return {'final_score': final_score,
            'component_scores': results,
            'confidence_level': self._calculate_confidence(results)
        }

    def _calculate_confidence(self, results):
        """–†–∞—Å—á–µ—Ç —É—Ä–æ–≤–Ω—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ"""
        scores = [v for k, v in results.items() if isinstance(v, (int, float))]
        #if len(scores) <= 1:
            #return 0.5
        
        # –ù–∏–∑–∫–∞—è –¥–∏—Å–ø–µ—Ä—Å–∏—è = –≤—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
        variance = np.var(scores)
        confidence = max(0.1, 1.0 - variance)
        return min(confidence, 0.95)

class SimplyClassificationMatcher:
    def __init__(self):
        # –í–µ—Å–æ–≤—ã–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤
        self.weights = {
            'skills_match': 0.35,      # –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ –Ω–∞–≤—ã–∫–æ–≤
            'experience_match': 0.25,   # –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –æ–ø—ã—Ç–∞
            'salary_match': 0.20,       # –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∑–∞—Ä–ø–ª–∞—Ç—ã
            'location_match': 0.15,     # –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –º–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏—è
            'education_match': 0.05     # –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è
        }
                
    def calculate_multi_criteria_score(self, resume_data, vacancy_data):
        """–ú–Ω–æ–≥–æ–∫—Ä–∏—Ç–µ—Ä–∏–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è"""
        criteria_scores = {}
        
        # 1. –û—Ü–µ–Ω–∫–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –Ω–∞–≤—ã–∫–æ–≤
        criteria_scores['skills_match'] = self._calculate_skills_match(resume_data, vacancy_data)
        # 2. –û—Ü–µ–Ω–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –æ–ø—ã—Ç–∞ —Ä–∞–±–æ—Ç—ã
        criteria_scores['experience_match'] = self._calculate_experience_match(resume_data, vacancy_data)
        # 3. –û—Ü–µ–Ω–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –∑–∞—Ä–ø–ª–∞—Ç–Ω—ã—Ö –æ–∂–∏–¥–∞–Ω–∏–π
        criteria_scores['salary_match'] = self._calculate_salary_match(resume_data, vacancy_data)
        # 4. –û—Ü–µ–Ω–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –º–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏—è
        criteria_scores['location_match'] = self._calculate_location_match(resume_data, vacancy_data)
        # 5. –û—Ü–µ–Ω–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è
        criteria_scores['education_match'] = self._calculate_education_match(resume_data)
        
        # –í—ã—á–∏—Å–ª—è–µ–º –≤–∑–≤–µ—à–µ–Ω–Ω—É—é –∏—Ç–æ–≥–æ–≤—É—é –æ—Ü–µ–Ω–∫—É
        final_score = sum(criteria_scores[criterion] * self.weights[criterion] for criterion in criteria_scores)
        
        return max(0.0, min(1.0, final_score))
    
    def _calculate_skills_match(self, resume_data, vacancy_data):
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –Ω–∞–≤—ã–∫–æ–≤ –º–µ–∂–¥—É —Ä–µ–∑—é–º–µ –∏ –≤–∞–∫–∞–Ω—Å–∏–µ–π"""
        try:
            resume_skills = self._extract_skills(resume_data.get_field('skills'))
            vacancy_skills = self._extract_skills(vacancy_data.get_field('key_skills'))
            
            if not vacancy_skills and not resume_skills:
                return 0.5  # –ù–µ–π—Ç—Ä–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –µ—Å–ª–∏ –Ω–∞–≤—ã–∫–∏ –Ω–µ —É–∫–∞–∑–∞–Ω—ã
            
            if not vacancy_skills:
                return 0.7  # –ï—Å–ª–∏ –≤ –≤–∞–∫–∞–Ω—Å–∏–∏ –Ω–µ —É–∫–∞–∑–∞–Ω—ã –Ω–∞–≤—ã–∫–∏, –Ω–æ –≤ —Ä–µ–∑—é–º–µ –µ—Å—Ç—å
            
            if not resume_skills:
                return 0.2  # –ï—Å–ª–∏ –≤ —Ä–µ–∑—é–º–µ –Ω–µ—Ç –Ω–∞–≤—ã–∫–æ–≤, –∞ –≤ –≤–∞–∫–∞–Ω—Å–∏–∏ –µ—Å—Ç—å
            
            # –¢–æ—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
            exact_matches = resume_skills.intersection(vacancy_skills)
            skills_score = len(exact_matches) / len(vacancy_skills)
            
            return min(1.0, skills_score)
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –Ω–∞–≤—ã–∫–æ–≤: {e}")
            return 0.0

    def _extract_skills(self, skills_data):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –Ω–∞–±–æ—Ä –Ω–∞–≤—ã–∫–æ–≤"""
        skills = set()
        
        if isinstance(skills_data, str):
            skills_list = [skill.strip().lower() for skill in skills_data.split(',')]
            skills.update(skill for skill in skills_list if skill)

        return skills

    def _calculate_experience_match(self, resume_data, vacancy_data):
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –æ–ø—ã—Ç–∞ —Ä–∞–±–æ—Ç—ã"""
        try:
            resume_exp_id = resume_data.get_field('experience_ID')
            vacancy_exp_id = vacancy_data.get_field('experience_id')
            
            if not resume_exp_id or not vacancy_exp_id:
                return 0.5  # –ù–µ–π—Ç—Ä–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç
            
            # –ü–æ–ª—É—á–∞–µ–º —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫ –æ–ø—ã—Ç–∞ —Ä–∞–±–æ—Ç—ã
            experience_dict = self._get_experience_mapping()
            
            resume_exp_level = experience_dict.get(resume_exp_id, 0)
            vacancy_exp_level = experience_dict.get(vacancy_exp_id, 0)
            
            # –í—ã—á–∏—Å–ª—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —É—Ä–æ–≤–Ω—è –æ–ø—ã—Ç–∞
            if resume_exp_level == vacancy_exp_level:
                return 1.0  # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
            elif abs(resume_exp_level - vacancy_exp_level) == 1:
                return 0.7  # –ë–ª–∏–∑–∫–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
            elif resume_exp_level > vacancy_exp_level:
                return 0.8  # –û–ø—ã—Ç –±–æ–ª—å—à–µ —Ç—Ä–µ–±—É–µ–º–æ–≥–æ
            else:
                return 0.3  # –û–ø—ã—Ç –º–µ–Ω—å—à–µ —Ç—Ä–µ–±—É–µ–º–æ–≥–æ
                
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –æ–ø—ã—Ç–∞: {e}")
            return 0.0

    def _get_experience_mapping(self):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–∞–ø–ø–∏–Ω–≥ ID –æ–ø—ã—Ç–∞ —Ä–∞–±–æ—Ç—ã –Ω–∞ —á–∏—Å–ª–æ–≤—ã–µ —É—Ä–æ–≤–Ω–∏"""
        return {
            'noExperience': 0,     # –ù–µ—Ç –æ–ø—ã—Ç–∞
            'between1And3': 1,     # –û—Ç 1 –≥–æ–¥–∞ –¥–æ 3 –ª–µ—Ç
            'between3And6': 2,     # –û—Ç 3 –¥–æ 6 –ª–µ—Ç
            'moreThan6': 3         # –ë–æ–ª–µ–µ 6 –ª–µ—Ç
        }


    def _calculate_salary_match(self, resume_data, vacancy_data):
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∑–∞—Ä–ø–ª–∞—Ç–Ω—ã—Ö –æ–∂–∏–¥–∞–Ω–∏–π"""
        try:
            resume_salary = resume_data.get_field('salary')
            vacancy_salary_from = vacancy_data.get_field('salary_from')
            vacancy_salary_to = vacancy_data.get_field('salary_to')
            
            if not resume_salary:
                return 0.5  # –ï—Å–ª–∏ –≤ —Ä–µ–∑—é–º–µ –Ω–µ —É–∫–∞–∑–∞–Ω–∞ –∑–∞—Ä–ø–ª–∞—Ç–∞
            
            if not vacancy_salary_from and not vacancy_salary_to:
                return 0.5  # –ï—Å–ª–∏ –≤ –≤–∞–∫–∞–Ω—Å–∏–∏ –Ω–µ —É–∫–∞–∑–∞–Ω–∞ –∑–∞—Ä–ø–ª–∞—Ç–∞
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω –∑–∞—Ä–ø–ª–∞—Ç—ã –≤ –≤–∞–∫–∞–Ω—Å–∏–∏
            if vacancy_salary_from and vacancy_salary_to:
                vacancy_min = vacancy_salary_from
                vacancy_max = vacancy_salary_to
            elif vacancy_salary_from:
                vacancy_min = vacancy_salary_from
                vacancy_max = vacancy_salary_from * 1.3  # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º –≤–µ—Ä—Ö–Ω—é—é –≥—Ä–∞–Ω–∏—Ü—É
            else:
                vacancy_min = vacancy_salary_to * 0.8  # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º –Ω–∏–∂–Ω—é—é –≥—Ä–∞–Ω–∏—Ü—É
                vacancy_max = vacancy_salary_to
            
            # –í—ã—á–∏—Å–ª—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ
            if vacancy_min <= resume_salary <= vacancy_max:
                return 1.0  # –ó–∞—Ä–ø–ª–∞—Ç–∞ –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ
            elif resume_salary < vacancy_min:
                # –ó–∞—Ä–ø–ª–∞—Ç–Ω—ã–µ –æ–∂–∏–¥–∞–Ω–∏—è –Ω–∏–∂–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
                diff_ratio = (vacancy_min - resume_salary) / vacancy_min
                return max(0.6, 1.0 - diff_ratio)
            else:
                # –ó–∞—Ä–ø–ª–∞—Ç–Ω—ã–µ –æ–∂–∏–¥–∞–Ω–∏—è –≤—ã—à–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
                diff_ratio = (resume_salary - vacancy_max) / vacancy_max
                return max(0.2, 1.0 - diff_ratio * 2)  # –ë–æ–ª–µ–µ –∂–µ—Å—Ç–∫–∞—è –æ—Ü–µ–Ω–∫–∞
                
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –∑–∞—Ä–ø–ª–∞—Ç—ã: {e}")
            return 0.0

    def _calculate_location_match(self, resume_data, vacancy_data):
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –º–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏—è"""
        try:
            resume_area = resume_data.get_field('area').lower().strip()
            vacancy_area = vacancy_data.get_field('area').lower().strip()
            
            if not resume_area or not vacancy_area:
                return 0.8  # –ù–µ–π—Ç—Ä–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç
            
            if resume_area == vacancy_area:
                return 1.0
            else:
                return 0.3

        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –º–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏—è: {e}")
            return 0.0

    def _calculate_education_match(self, resume_data):
        """–í—ã—á–∏—Å–ª—è–µ—Ç —É—Ä–æ–≤–µ–Ω—å –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è"""
        try:
            resume_education = resume_data.get_field('education').lower()
            
            if not resume_education:
                return 0.5  # –ù–µ–π—Ç—Ä–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –µ—Å–ª–∏ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –Ω–µ —É–∫–∞–∑–∞–Ω–æ
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Ä–æ–≤–µ–Ω—å –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è
            if any(keyword in resume_education for keyword in ['—É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç', '–∏–Ω—Å—Ç–∏—Ç—É—Ç', '–∞–∫–∞–¥–µ–º–∏—è']):
                return 1.0  # –í—ã—Å—à–µ–µ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ
            elif any(keyword in resume_education for keyword in ['–∫–æ–ª–ª–µ–¥–∂', '—Ç–µ—Ö–Ω–∏–∫—É–º']):
                return 0.8  # –°—Ä–µ–¥–Ω–µ–µ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ–µ
            elif any(keyword in resume_education for keyword in ['—à–∫–æ–ª–∞', '–ª–∏—Ü–µ–π', '–≥–∏–º–Ω–∞–∑–∏—è']):
                return 0.6  # –°—Ä–µ–¥–Ω–µ–µ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ
            else:
                return 0.5  # –ù–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–µ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ
                
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è: {e}")
            return 0.0

class Word2VecMatcher:
    def __init__(self, word2vec_model):
        self.word2vec_model = word2vec_model

    def calculate_similarity(self, resume_data, vacancy_data):
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞ –º–µ–∂–¥—É —Ä–µ–∑—é–º–µ –∏ –≤–∞–∫–∞–Ω—Å–∏–µ–π"""
        try:
            resume_vector = self.text_to_vector(self._extract_text(resume_data))
            vacancy_vector = self.text_to_vector(self._extract_text(vacancy_data))

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤–µ–∫—Ç–æ—Ä—ã –ø–æ–ª—É—á–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ
            if resume_vector is None or vacancy_vector is None:
                print("–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –≤–µ–∫—Ç–æ—Ä—ã –¥–ª—è —Ä–µ–∑—é–º–µ –∏–ª–∏ –≤–∞–∫–∞–Ω—Å–∏–∏")
                return 0.0
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –≤–µ–∫—Ç–æ—Ä–æ–≤
            if resume_vector.size == 0 or vacancy_vector.size == 0:
                print("–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ü–æ–ª—É—á–µ–Ω—ã –ø—É—Å—Ç—ã–µ –≤–µ–∫—Ç–æ—Ä—ã")
                return 0.0
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤–µ–∫—Ç–æ—Ä—ã –∏–º–µ—é—Ç –æ–¥–∏–Ω–∞–∫–æ–≤—É—é —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å
            if resume_vector.shape != vacancy_vector.shape:
                print(f"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –í–µ–∫—Ç–æ—Ä—ã –∏–º–µ—é—Ç —Ä–∞–∑–Ω—ã–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏: {resume_vector.shape} vs {vacancy_vector.shape}")
                return 0.0
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ NaN –∏ –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ—Å—Ç—å
            if np.any(np.isnan(resume_vector)) or np.any(np.isnan(vacancy_vector)):
                print("–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã NaN –∑–Ω–∞—á–µ–Ω–∏—è –≤ –≤–µ–∫—Ç–æ—Ä–∞—Ö")
                return 0.0
            
            if np.any(np.isinf(resume_vector)) or np.any(np.isinf(vacancy_vector)):
                print("–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –±–µ—Å–∫–æ–Ω–µ—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ –≤–µ–∫—Ç–æ—Ä–∞—Ö")
                return 0.0
            
            # Reshape –¥–ª—è cosine_similarity (–¥–æ–ª–∂–Ω—ã –±—ã—Ç—å 2D –º–∞—Å—Å–∏–≤—ã)
            resume_vector = resume_vector.reshape(1, -1)
            vacancy_vector = vacancy_vector.reshape(1, -1)
            
            # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ
            similarity = cosine_similarity(resume_vector, vacancy_vector)[0][0]
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å
            if np.isnan(similarity) or np.isinf(similarity):
                print("–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ü–æ–ª—É—á–µ–Ω–æ –Ω–µ–≤–∞–ª–∏–¥–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Å—Ö–æ–¥—Å—Ç–≤–∞")
                return 0.0
            
            return max(0.0, min(1.0, similarity))  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –º–µ–∂–¥—É 0 –∏ 1
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏–∏ —Å—Ö–æ–¥—Å—Ç–≤–∞: {e}")
            return 0.0


    def text_to_vector(self, text):
        """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –≤ –≤–µ–∫—Ç–æ—Ä –∏—Å–ø–æ–ª—å–∑—É—è Word2Vec"""
        if not self.word2vec_model or not text:
            return None

        words = self._clean_text(text).split()
        if not words:
            return None
        
        word_vectors = []

        for word in words:
            try:
                if word in self.word2vec_model.wv:
                    word_vectors.append(self.word2vec_model.wv[word])
            except (KeyError, AttributeError):
                continue

        if not word_vectors:
            return np.zeros(self.word2vec_model.vector_size if hasattr(self.word2vec_model, 'vector_size') else 100)

        word_vectors = np.array(word_vectors)

        if word_vectors.ndim == 1:
            return word_vectors
        elif word_vectors.ndim == 2:
            return np.mean(word_vectors, axis=0)
        else:
            return np.zeros(self.word2vec_model.vector_size if hasattr(self.word2vec_model, 'vector_size') else 100)

    def _extract_text(self, HH_data):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"""
        text_parts = []
        
        if isinstance(HH_data, HH.ResumeData):
            fields_to_extract = ['description', 'description_about_me']
        elif isinstance(HH_data, HH.VacancyData):
            fields_to_extract = ['description']

        for field in fields_to_extract:
            try:
                field_value = HH_data.get_field(field)
                if field_value and isinstance(field_value, str):
                    text_parts.append(field_value)
            except (AttributeError, KeyError):
                continue

        full_text = ' '.join(text_parts)
        full_text = self._clean_text(full_text)
        return full_text

    def _clean_text(self, text):
        """–û—á–∏—Å—Ç–∫–∞ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞"""
        if not text:
            return ""
        
        text = re.sub(r'\s+', ' ', text)
        text = re.sub(r'[^\w\s]', ' ', text)
        text = text.lower().strip()
        return text
    

def load_word2vec_model():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ Word2Vec"""
    word2vec_model = None
    try:
        word2vec_model = word2vec.load_model()
        if word2vec_model is None:
            print("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å Word2Vec")
        else:
            print("–ú–æ–¥–µ–ª—å Word2Vec –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
    return word2vec_model

def load_data(data_type='vacancies', proc_type='download'):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Ö–æ–¥—è—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö"""
    data_from_csv = None
    input_object = None
    objects_list = []
    if proc_type == 'download':
        if data_type == 'vacancies':
            input_object = HH.download_vacancies_from_hh()[1]
        elif data_type == 'resumes':
            input_object = HH.download_resumes_from_hh()[1]
    elif proc_type == 'file':
        data_from_csv = HH.load_from_csv(data_type)
        if data_from_csv is not None:
            if data_type == 'vacancies':
                input_object = HH.select_from_dataframe(HH.VacancyData(), data_from_csv)
            elif data_type == 'resumes':
                input_object = HH.select_from_dataframe(HH.ResumeData(), data_from_csv)

    if input_object is not None:
        objects_list = input_data(input_object)
    else:
        print(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ {data_type}.")
    return objects_list

def input_data(data):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö"""
    objects_list = []
    try:
        if isinstance(data, list):
            for item in data:
                if isinstance(item, HH.ResumeData) or isinstance(item, HH.VacancyData):
                    objects_list.append(item)
            print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(data)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤")
        elif isinstance(data, HH.VacancyData) or isinstance(data, HH.ResumeData):
            objects_list.append(data)
            print(f"{data.__class__.__name__} –¥–æ–±–∞–≤–ª–µ–Ω–æ –≤ —Å–ø–∏—Å–æ–∫: {data.get_header_text()}")
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
    return objects_list

def initialize_necessary_components():
    word2vec_model = load_word2vec_model()
    resume_objects_list = load_data('resumes', 'file')
    vacancies_objects_list = load_data('vacancies', 'file')
    return word2vec_model, resume_objects_list, vacancies_objects_list


def run_ultimate_matching():
    word2vec_model, resume_objects_list, vacancies_objects_list = initialize_necessary_components()

    if not word2vec_model:
        print("–°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –º–æ–¥–µ–ª—å Word2Vec")
        return

    if not resume_objects_list or not vacancies_objects_list:
        print("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ä–µ–∑—é–º–µ –∏ –≤–∞–∫–∞–Ω—Å–∏–∏")
        return
    
    matches = []
    experience_dict = HH.get_hh_dictionaries('experience')

    print(f"–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è —Ä–µ–∑—é–º–µ –∏ –≤–∞–∫–∞–Ω—Å–∏–π...")
    for resume in resume_objects_list:
        best_matches = []

        for vacancy in vacancies_objects_list:
            matcher = UltimateMatcher(word2vec_model, resume, vacancy)
            match_result = matcher.ultimate_match()
            
            if match_result['final_score'] > 0.5:
                best_matches.append({
                    'vacancy_id': vacancy.get_field('vacancy_id'),
                    'vacancy_name': vacancy.get_header_text(),
                    'similarity': round(match_result['final_score'], 4),
                    'confidence_level': round(match_result['confidence_level'], 4),
                    'company': vacancy.get_field('employer_name'),
                    'area': vacancy.get_field('area'),
                    'url': vacancy.get_field('url'),
                    'experience': get_hh_experience_by_id(experience_dict, vacancy.get_field('experience_id')),
                    'component_scores': match_result.get('component_scores', {})
                })

        if best_matches:
            matches.append({
                'resume_id': resume.get_field('resume_id'),
                'resume_name': resume.get_field('name'),
                'url': resume.get_field('url'),
                'matches': best_matches,
                'total_matches_found': len(best_matches)
            })    
    return matches


def get_hh_experience_by_id(experience_dict, experience_id):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ –æ–ø—ã—Ç–∞ —Ä–∞–±–æ—Ç—ã –ø–æ –µ–≥–æ ID."""
    try:
        for exp in experience_dict:
            if exp.get('id') == experience_id:
                return exp.get('name')
    except:
        return None

def display_matches(matches):
        """–û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è"""
        if not matches:
            print("–°–æ–≤–ø–∞–¥–µ–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
            return
        
        total_resumes = len(matches)
        total_matches = sum(len(match['matches']) for match in matches)
        
        print(f"\n{'='*80}")
        print(f"–†–ï–ó–£–õ–¨–¢–ê–¢–´ –°–û–ü–û–°–¢–ê–í–õ–ï–ù–ò–Ø")
        print(f"{'='*80}")
        print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ä–µ–∑—é–º–µ: {total_resumes}")
        print(f"–í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π: {total_matches}")
        print(f"{'='*80}")
        
        for match in matches:
            print(f"\nüìÑ –†–ï–ó–Æ–ú–ï: {match['resume_name']}")
            print(f"   ID –Ω–∞ HeadHunter: {match['resume_id']}")
            print(f"   –°—Å—ã–ª–∫–∞: {match['url']}")

            if not match['matches']:
                print("‚ùå –ü–æ–¥—Ö–æ–¥—è—â–∏—Ö –≤–∞–∫–∞–Ω—Å–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
                continue
            else:
                print(f"   –ù–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π: {match['total_matches_found']}")
            
            print(f"{'‚îÄ'*80}")

            for i, vacancy_match in enumerate(match['matches'], 1):
                similarity_percent = vacancy_match['similarity'] * 100
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Ä–æ–≤–µ–Ω—å —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
                if similarity_percent >= 80:
                    level = "üü¢ –û–¢–õ–ò–ß–ù–û–ï"
                elif similarity_percent >= 60:
                    level = "üü° –•–û–†–û–®–ï–ï"
                elif similarity_percent >= 40:
                    level = "üü† –°–†–ï–î–ù–ï–ï"
                else:
                    level = "üî¥ –°–õ–ê–ë–û–ï"
                
                print(f"\n   {i}. üíº {vacancy_match['vacancy_name']}")
                print(f"      üè¢ –ö–æ–º–ø–∞–Ω–∏—è: {vacancy_match['company']}")
                print(f"      üìç –†–µ–≥–∏–æ–Ω: {vacancy_match['area']}")
                print(f"      üìä –°—Ö–æ–¥—Å—Ç–≤–æ: {similarity_percent:.1f}% ({vacancy_match['confidence_level']:.1f}) ({level})")
                print(f"      üéØ –û–ø—ã—Ç: {vacancy_match['experience']}")
                print(f"      üîó –°—Å—ã–ª–∫–∞: {vacancy_match['url']}")
                print(f"      üìù –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã: {', '.join([f'{comp}: {score:.1f}' for comp, score in vacancy_match['component_scores'].items()])}")

        print(f"\n{'='*80}")
        print("–°–æ–≤–µ—Ç: –†–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–π—Ç–µ –≤–∞–∫–∞–Ω—Å–∏–∏ —Å —Å—Ö–æ–¥—Å—Ç–≤–æ–º –≤—ã—à–µ 60% –∫–∞–∫ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ")
        print(f"{'='*80}")

def ultimate_matching_menu():
    action = ''

    while action != '–í—ã—Ö–æ–¥':
        select_mode = [
            '–í—ã–ø–æ–ª–Ω–∏—Ç—å —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ',
            '–í—ã—Ö–æ–¥'
        ]

        if action == '':
            action = pick(select_mode, '–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ –æ–ø—Ü–∏—é:', indicator='>')[0]
            
        try:
            if action == '–í—ã–ø–æ–ª–Ω–∏—Ç—å —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ':
                matches = run_ultimate_matching()
                display_matches(matches)
                input("–ù–∞–∂–º–∏—Ç–µ –ª—é–±—É—é –∫–ª–∞–≤–∏—à—É –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è...")
                action = ''
            else:
                print("–í—ã—Ö–æ–¥ –∏–∑ –º–æ–¥—É–ª—è...")
                break
        except Exception as e:
            print(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}")
            input("–ù–∞–∂–º–∏—Ç–µ –ª—é–±—É—é –∫–ª–∞–≤–∏—à—É –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è...")
            action = ''


if __name__ == "__main__":
    ultimate_matching_menu()